# --- [7G] Summary ---
[52e4]-181022.1148 ->- e2eET.liveStream-DHG1428.3D.7G-[cm_td_fa]-i25 ->- -- [ i224a] - 0.7288 - 0.7240 - 0.7530 - 0.8257 - 00:28
[52e4]-181022.1148 ->- e2eET.liveStream-DHG1428.3D.7G-[cm_td_fa]-i25 ->- -- [ i224b] - 0.7821 - 0.8039 - 0.8305 - 0.8935 - 01:00
[52e4]-181022.1148 ->- e2eET.liveStream-DHG1428.3D.7G-[cm_td_fa]-i25 ->- -- [i224bf] - 0.7700 - 0.8208 - 0.8354 - 0.8983 - 01:15
[52e4]-181022.1148 ->- e2eET.liveStream-DHG1428.3D.7G-[cm_td_fa]-i25 ->- accuracies@e2eT: {'Custom': 0.77, 'Top-Down': 0.8208, 'Front-Away': 0.8354, 'Tuner': 0.8983}
[52e4]-181022.1148 ->- e2eET.liveStream-DHG1428.3D.7G-[cm_td_fa]-i25 ->- e2eT_MaxA: 0.8983 @01h:16m:07s
# ---
[bf75]-181022.1321 ->- e2eET.liveStream-DHG1428.3D.7G-[cm_td_fa]-i30.10 ->- -- [ i224a] - 0.7167 - 0.7506 - 0.7797 - 0.8523 - 00:33
[bf75]-181022.1321 ->- e2eET.liveStream-DHG1428.3D.7G-[cm_td_fa]-i30.10 ->- -- [ i224b] - 0.8257 - 0.8426 - 0.8547 - 0.9249 - 01:11
[bf75]-181022.1321 ->- e2eET.liveStream-DHG1428.3D.7G-[cm_td_fa]-i30.10 ->- -- [i224bf] - 0.8668 - 0.8281 - 0.8596 - 0.9346 - 01:29
[bf75]-181022.1321 ->- e2eET.liveStream-DHG1428.3D.7G-[cm_td_fa]-i30.10 ->- -- [   276] - 0.8668 - 0.8281 - 0.8596 - 0.9346 - 02:01
[bf75]-181022.1321 ->- e2eET.liveStream-DHG1428.3D.7G-[cm_td_fa]-i30.10 ->- -- [   328] - 0.8668 - 0.8281 - 0.8596 - 0.9346 - 03:03
[bf75]-181022.1321 ->- e2eET.liveStream-DHG1428.3D.7G-[cm_td_fa]-i30.10 ->- accuracies@e2eT: {'Custom': 0.8039, 'Top-Down': 0.6901, 'Front-Away': 0.7482, 'Tuner': 0.2881}
[bf75]-181022.1321 ->- e2eET.liveStream-DHG1428.3D.7G-[cm_td_fa]-i30.10 ->- e2eT_MaxA: 0.9346 @03h:03m:54s
# ------------------------------------------------------------------------


# --- [7G] Details ---
deets.e_tag='e2eEnsembleTunerTraining'
deets.e_secret='52e4'
e_strftime='181022.1148'
deets.e_desc='e2eET.liveStream-DHG1428.3D.7G-[cm_td_fa]-i25'
deets.ds_directory='./.sources/DHG1428.liveStream-3D.14G-[custom.topdown.frontaway]'
e_args=
	idx_gpu                   -- <class 'int'>   -- 1
	n_classes                 -- <class 'int'>   -- 7
	mv_orientations           -- <class 'list'>  -- ['custom', 'top-down', 'front-away']
	nd                        -- <class 'str'>   -- 3d
	bs                        -- <class 'int'>   -- 16
	init_img_sz               -- <class 'int'>   -- 224
	init_eps                  -- <class 'int'>   -- 25
	init_itr_scl_eps          -- <class 'int'>   -- 0
	itr_scl_sizes             -- <class 'list'>  -- [0]
	itr_scl_eps               -- <class 'int'>   -- 5
	itr_finetuning            -- <class 'bool'>  -- False
	create_e_tb_events        -- <class 'bool'>  -- False
	create_e_model_checkpoint -- <class 'bool'>  -- True
	verbose                   -- <class 'bool'>  -- False
	e_history                 -- <class 'list'>  -- []
---------------

Dataloader has been created successfully...
The dataloader has 7 (7) classes: ['Swipe+', 'SwipeDown', 'SwipeLeft', 'SwipeRight', 'SwipeUp', 'SwipeV', 'SwipeX']
Training set [len=987, img_sz=(960, 960)] loaded on device: cuda:1
Validation set [len=413, img_sz=(960, 960)] loaded on device: cuda:1
Previewing loaded data [1] and applied transforms [2]...


metrics= [<bound method accuracyMultiVOs_0 of e2eTunerLossWrapper()>, <bound method accuracyMultiVOs_1 of e2eTunerLossWrapper()>, <bound method accuracyMultiVOs_2 of e2eTunerLossWrapper()>, <bound method e2eTunerLossWrapper.accuracyTuner of e2eTunerLossWrapper()>]
Batch Size: 16, Image Size: 224, Epochs: [25, 25]

Model FROZEN [a].
>> @i224a --- pct_start: 0.35 --- learning_rate: 0.0003981071640737355
epoch     train_loss  valid_loss  accuracyCustom  accuracyTopDown  accuracyFrontAway  accuracyTuner  time
0         6.829398    5.965680    0.450363        0.452785         0.438257           0.452785       01:01
1         5.929319    5.248991    0.489104        0.496368         0.542373           0.554479       01:04
2         5.431876    4.835974    0.525424        0.496368         0.566586           0.627119       01:01
3         4.980965    4.340788    0.581114        0.569007         0.656174           0.644068       01:04
4         4.760147    3.851085    0.629540        0.622276         0.685230           0.721550       01:01
5         4.489138    3.696330    0.634383        0.644068         0.670702           0.736077       01:05
6         4.257139    3.723460    0.651332        0.631961         0.665860           0.709443       01:03
7         4.246898    3.390704    0.709443        0.663438         0.719128           0.782082       01:04
8         4.020936    3.442410    0.687651        0.646489         0.697337           0.760291       01:03
9         3.889587    3.255167    0.670702        0.702179         0.709443           0.765133       01:03
10        3.700030    3.748931    0.634383        0.663438         0.680387           0.692494       01:04
11        3.671640    3.340786    0.677966        0.707022         0.704601           0.755448       01:03
12        3.398415    3.476367    0.699758        0.663438         0.702179           0.740920       01:06
13        3.253538    2.895940    0.714286        0.721550         0.748184           0.818402       01:01
14        3.265199    3.115740    0.675545        0.699758         0.745763           0.791768       01:04
15        3.001412    3.125408    0.682809        0.704601         0.748184           0.791768       01:01
16        2.966930    3.147088    0.687651        0.694915         0.750605           0.769976       01:04
17        3.019053    3.049309    0.709443        0.677966         0.755448           0.782082       01:02
18        2.856044    2.876852    0.728814        0.723971         0.753027           0.825666       01:06
19        2.735705    2.966358    0.733656        0.685230         0.753027           0.803874       01:04
20        2.769014    2.972110    0.697337        0.721550         0.740920           0.799031       01:03
21        2.660561    2.919865    0.723971        0.711864         0.753027           0.794189       01:03
22        2.596250    3.088220    0.702179        0.694915         0.740920           0.791768       01:03
23        2.663255    3.015824    0.702179        0.726392         0.748184           0.794189       01:05
24        2.620908    2.981073    0.711864        0.702179         0.745763           0.796610       01:01
@outsidersCustomCallback: Training completed and best i224a model loaded!
-- [ i224a] - 0.7288 - 0.7240 - 0.7530 - 0.8257 - 00:28

Model UNFROZEN [b].
>> @i224b --- pct_start: 0.35 --- learning_rate: 3.630780702224001e-05
epoch     train_loss  valid_loss  accuracyCustom  accuracyTopDown  accuracyFrontAway  accuracyTuner  time
0         3.305558    3.308856    0.677966        0.685230         0.757869           0.791768       01:14
1         2.808572    3.117860    0.646489        0.709443         0.769976           0.796610       01:14
2         2.611966    2.866411    0.702179        0.753027         0.774818           0.801453       01:15
3         2.592210    2.460824    0.716707        0.806295         0.808717           0.874092       01:14
4         2.322078    2.504411    0.738499        0.794189         0.806295           0.852300       01:14
5         2.206845    2.375463    0.738499        0.767554         0.832930           0.845036       01:15
6         2.144871    2.340608    0.736077        0.806295         0.799031           0.871671       01:12
7         1.967351    2.565853    0.694915        0.796610         0.806295           0.837772       01:17
8         1.926934    2.655811    0.704601        0.777240         0.803874           0.811138       01:15
9         1.826861    2.276198    0.748184        0.806295         0.818402           0.874092       01:12
10        1.656807    2.444773    0.743341        0.777240         0.799031           0.852300       01:15
11        1.509253    2.110442    0.750605        0.825666         0.823245           0.871671       01:14
12        1.402457    2.253421    0.782082        0.791768         0.806295           0.874092       01:14
13        1.270428    2.136064    0.774818        0.818402         0.813559           0.881356       01:15
14        1.150468    2.380049    0.755448        0.789346         0.806295           0.869249       01:14
15        1.121303    2.216799    0.777240        0.779661         0.840194           0.876513       01:14
16        1.011933    2.337172    0.784504        0.786925         0.815981           0.876513       01:15
17        0.886086    2.094229    0.782082        0.803874         0.830508           0.893462       01:14
18        0.898384    2.307835    0.755448        0.784504         0.825666           0.869249       01:12
19        0.769309    2.236957    0.750605        0.806295         0.813559           0.864407       01:15
20        0.795222    2.110984    0.762712        0.815981         0.828087           0.869249       01:12
21        0.714633    2.259284    0.760291        0.799031         0.818402           0.878935       01:16
22        0.731730    2.198570    0.772397        0.806295         0.808717           0.871671       01:14
23        0.733517    2.107942    0.774818        0.818402         0.823245           0.876513       01:15
24        0.701317    2.217282    0.774818        0.806295         0.823245           0.869249       01:14
@outsidersCustomCallback: Training completed and best i224b model loaded!
-- [ i224b] - 0.7821 - 0.8039 - 0.8305 - 0.8935 - 01:00
>> @i224bf --- pct_start: 0.35 --- learning_rate: 3.6307807022240014e-06
epoch     train_loss  valid_loss  accuracyCustom  accuracyTopDown  accuracyFrontAway  accuracyTuner  time
0         0.801726    2.203358    0.765133        0.803874         0.815981           0.878935       01:14
1         0.811300    2.064310    0.765133        0.825666         0.825666           0.886199       01:14
2         0.796131    2.046977    0.769976        0.820823         0.835351           0.898305       01:15
3         0.816795    2.117744    0.757869        0.818402         0.828087           0.881356       01:17
4         0.775851    2.173162    0.745763        0.832930         0.820823           0.881356       01:13
5         0.724065    2.232569    0.777240        0.774818         0.820823           0.874092       01:15
6         0.679087    2.214297    0.750605        0.820823         0.811138           0.869249       01:12
7         0.643317    2.219917    0.760291        0.806295         0.820823           0.871671       01:15
8         0.659398    2.250178    0.767554        0.808717         0.808717           0.861985       01:12
9         0.705989    2.203172    0.755448        0.818402         0.828087           0.876513       01:16
10        0.689540    2.168539    0.755448        0.828087         0.818402           0.886199       01:12
11        0.625369    2.191130    0.757869        0.830508         0.803874           0.869249       01:15
@outsidersCustomCallback: Training completed and best i224bf model loaded!
-- [i224bf] - 0.7700 - 0.8208 - 0.8354 - 0.8983 - 01:15
Time Elapsed ~ 01h:15m:54s
accuracies@e2eT: {'Custom': 0.77, 'Top-Down': 0.8208, 'Front-Away': 0.8354, 'Tuner': 0.8983}
Learner pkl and pt checkpoints created successfully
e2eT_MaxA: 0.8983 @01h:16m:07s
Training completed @e2eEnsembleTunerTraining ->> [52e4]-181022.1148 ->- e2eET.liveStream-DHG1428.3D.7G-[cm_td_fa]-i25
# ------------------------------------------------------------------------
# ------------------------------------------------------------------------


deets.e_tag='e2eEnsembleTunerTraining'
deets.e_secret='bf75'
e_strftime='181022.1321'
deets.e_desc='e2eET.liveStream-DHG1428.3D.7G-[cm_td_fa]-i30.10'
deets.ds_directory='./.sources/DHG1428.liveStream-3D.14G-[custom.topdown.frontaway]'
e_args=
	idx_gpu                   -- <class 'int'>   -- 1
	n_classes                 -- <class 'int'>   -- 7
	mv_orientations           -- <class 'list'>  -- ['custom', 'top-down', 'front-away']
	nd                        -- <class 'str'>   -- 3d
	bs                        -- <class 'int'>   -- 16
	init_img_sz               -- <class 'int'>   -- 224
	init_eps                  -- <class 'int'>   -- 30
	init_itr_scl_eps          -- <class 'int'>   -- 0
	itr_scl_sizes             -- <class 'list'>  -- [276, 328]
	itr_scl_eps               -- <class 'int'>   -- 10
	itr_finetuning            -- <class 'bool'>  -- False
	create_e_tb_events        -- <class 'bool'>  -- False
	create_e_model_checkpoint -- <class 'bool'>  -- True
	verbose                   -- <class 'bool'>  -- False
	e_history                 -- <class 'list'>  -- []
---------------

Dataloader has been created successfully...
The dataloader has 7 (7) classes: ['Swipe+', 'SwipeDown', 'SwipeLeft', 'SwipeRight', 'SwipeUp', 'SwipeV', 'SwipeX']
Training set [len=987, img_sz=(960, 960)] loaded on device: cuda:1
Validation set [len=413, img_sz=(960, 960)] loaded on device: cuda:1
Previewing loaded data [1] and applied transforms [2]...


metrics= [<bound method accuracyMultiVOs_0 of e2eTunerLossWrapper()>, <bound method accuracyMultiVOs_1 of e2eTunerLossWrapper()>, <bound method accuracyMultiVOs_2 of e2eTunerLossWrapper()>, <bound method e2eTunerLossWrapper.accuracyTuner of e2eTunerLossWrapper()>]
Batch Size: 16, Image Size: 224, Epochs: [30, 30]

Model FROZEN [a].
>> @i224a --- pct_start: 0.6 --- learning_rate: 0.0003981071640737355
epoch     train_loss  valid_loss  accuracyCustom  accuracyTopDown  accuracyFrontAway  accuracyTuner  time
0         6.829398    5.965680    0.450363        0.452785         0.438257           0.452785       01:04
1         5.929319    5.248991    0.489104        0.496368         0.542373           0.554479       01:01
2         5.431876    4.835974    0.525424        0.496368         0.566586           0.627119       01:05
3         4.980965    4.340788    0.581114        0.569007         0.656174           0.644068       01:02
4         4.760147    3.851085    0.629540        0.622276         0.685230           0.721550       01:04
5         4.489138    3.696330    0.634383        0.644068         0.670702           0.736077       01:01
6         4.257139    3.723460    0.651332        0.631961         0.665860           0.709443       01:05
7         4.246898    3.390704    0.709443        0.663438         0.719128           0.782082       01:02
8         4.020926    3.442300    0.687651        0.646489         0.697337           0.760291       01:03
9         3.890613    3.291938    0.661017        0.694915         0.704601           0.748184       01:04
10        3.699281    3.771935    0.636804        0.665860         0.677966           0.687651       01:04
11        3.673486    3.324919    0.685230        0.709443         0.690073           0.760291       01:04
12        3.412691    3.497844    0.687651        0.658596         0.711864           0.736077       01:01
13        3.306236    2.986351    0.697337        0.699758         0.750605           0.799031       01:06
14        3.327264    3.099921    0.675545        0.699758         0.740920           0.803874       01:01
15        3.079813    3.126591    0.685230        0.697337         0.743341           0.796610       01:05
16        3.079058    3.156431    0.687651        0.665860         0.760291           0.765133       01:01
17        3.123353    3.051152    0.726392        0.658596         0.736077           0.769976       01:05
18        2.926923    2.954298    0.714286        0.709443         0.743341           0.765133       01:02
19        2.818006    2.974282    0.733656        0.646489         0.769976           0.794189       01:04
20        2.821424    2.910294    0.694915        0.716707         0.738499           0.823245       01:02
21        2.649893    2.910426    0.719128        0.709443         0.774818           0.813559       01:04
22        2.612353    2.886795    0.702179        0.723971         0.769976           0.818402       01:04
23        2.580506    2.891421    0.670702        0.750605         0.772397           0.835351       01:02
24        2.450344    2.684684    0.719128        0.723971         0.782082           0.832930       01:05
25        2.256724    2.578856    0.719128        0.745763         0.801453           0.852300       01:01
26        2.320689    2.880634    0.692494        0.709443         0.762712           0.820823       01:05
27        2.226840    2.632863    0.719128        0.719128         0.786925           0.837772       01:01
28        2.064695    2.714433    0.709443        0.707022         0.786925           0.832930       01:06
29        2.167255    2.561203    0.716707        0.750605         0.779661           0.852300       01:02
@outsidersCustomCallback: Training completed and best i224a model loaded!
-- [ i224a] - 0.7167 - 0.7506 - 0.7797 - 0.8523 - 00:33

Model UNFROZEN [b].
>> @i224b --- pct_start: 0.6 --- learning_rate: 9.120108734350652e-05
epoch     train_loss  valid_loss  accuracyCustom  accuracyTopDown  accuracyFrontAway  accuracyTuner  time
0         3.771223    3.449666    0.668281        0.653753         0.750605           0.658596       01:13
1         3.203213    2.638990    0.702179        0.762712         0.799031           0.815981       01:15
2         2.803150    2.762560    0.716707        0.753027         0.777240           0.806295       01:12
3         2.602003    2.593124    0.745763        0.760291         0.784504           0.832930       01:16
4         2.361170    2.365784    0.753027        0.772397         0.796610           0.847458       01:15
5         2.180205    2.604641    0.748184        0.772397         0.777240           0.835351       01:14
6         1.973596    2.452671    0.748184        0.765133         0.823245           0.852300       01:14
7         1.793128    2.131828    0.779661        0.806295         0.847458           0.874092       01:13
8         1.760400    2.169883    0.794189        0.791768         0.842615           0.869249       01:10
9         1.572499    2.839051    0.723971        0.731235         0.772397           0.789346       01:10
10        1.480965    2.487819    0.748184        0.774818         0.803874           0.837772       01:10
11        1.340625    2.537801    0.680387        0.825666         0.828087           0.871671       01:10
12        1.269060    2.785723    0.704601        0.760291         0.791768           0.815981       01:10
13        1.338254    2.503320    0.723971        0.731235         0.835351           0.825666       01:10
14        1.252745    2.572500    0.723971        0.791768         0.820823           0.842615       01:10
15        1.323048    2.089968    0.811138        0.789346         0.837772           0.864407       01:10
16        1.175498    2.107891    0.765133        0.794189         0.832930           0.891041       01:10
17        1.084979    2.617939    0.774818        0.743341         0.818402           0.842615       01:10
18        1.023504    2.315687    0.820823        0.723971         0.849879           0.878935       01:10
19        0.911032    2.363824    0.786925        0.779661         0.823245           0.842615       01:10
20        0.821573    2.623984    0.774818        0.762712         0.813559           0.852300       01:10
21        0.757521    2.320714    0.765133        0.794189         0.825666           0.861985       01:10
22        0.696438    1.921124    0.825666        0.828087         0.840194           0.895884       01:10
23        0.640257    2.065663    0.801453        0.837772         0.837772           0.900726       01:10
24        0.489536    2.089669    0.815981        0.828087         0.854722           0.893462       01:10
25        0.438748    1.972132    0.835351        0.806295         0.849879           0.907990       01:10
26        0.353797    1.821552    0.825666        0.842615         0.854722           0.924939       01:10
27        0.295199    1.952971    0.852300        0.818402         0.864407           0.917676       01:10
28        0.259738    1.806556    0.835351        0.859564         0.842615           0.910412       01:10
29        0.316624    1.831675    0.849879        0.820823         0.878935           0.917676       01:10
@outsidersCustomCallback: Training completed and best i224b model loaded!
-- [ i224b] - 0.8257 - 0.8426 - 0.8547 - 0.9249 - 01:11
>> @i224bf --- pct_start: 0.6 --- learning_rate: 9.120108734350651e-06
epoch     train_loss  valid_loss  accuracyCustom  accuracyTopDown  accuracyFrontAway  accuracyTuner  time
0         0.271064    1.823222    0.823245        0.837772         0.849879           0.912833       01:10
1         0.271776    1.835426    0.847458        0.832930         0.859564           0.915254       01:10
2         0.255059    1.970369    0.854722        0.794189         0.861985           0.922518       01:10
3         0.285178    2.039112    0.820823        0.828087         0.852300           0.907990       01:10
4         0.292307    2.022331    0.825666        0.818402         0.859564           0.910412       01:10
5         0.242399    1.946528    0.828087        0.835351         0.869249           0.907990       01:10
6         0.260119    1.827134    0.849879        0.825666         0.866828           0.922518       01:10
7         0.319634    1.760425    0.852300        0.847458         0.864407           0.934625       01:10
8         0.280494    1.766265    0.866828        0.828087         0.859564           0.934625       01:10
9         0.242470    1.753124    0.847458        0.828087         0.866828           0.924939       01:10
10        0.244534    2.061235    0.825666        0.789346         0.869249           0.915254       01:10
11        0.203945    1.899639    0.837772        0.832930         0.854722           0.927361       01:10
12        0.212152    2.088183    0.825666        0.828087         0.847458           0.910412       01:10
13        0.199046    1.962978    0.859564        0.789346         0.854722           0.920097       01:10
14        0.199591    1.999172    0.828087        0.815981         0.866828           0.927361       01:10
@outsidersCustomCallback: Training completed and best i224bf model loaded!
-- [i224bf] - 0.8668 - 0.8281 - 0.8596 - 0.9346 - 01:29
Time Elapsed ~ 01h:29m:22s
Batch Size: 16, Image Size: 276, Epochs: 10

Model FROZEN [a].
>> @276a --- pct_start: 0.2 --- learning_rate: 0.00015848931798245758
epoch     train_loss  valid_loss  accuracyCustom  accuracyTopDown  accuracyFrontAway  accuracyTuner  time
0         0.388371    1.842560    0.832930        0.842615         0.876513           0.910412       01:19
1         0.330973    1.759241    0.859564        0.830508         0.886199           0.920097       01:19
2         0.278715    1.910249    0.847458        0.825666         0.881356           0.905569       01:19
3         0.255803    1.921279    0.830508        0.847458         0.876513           0.915254       01:19
4         0.240103    1.863638    0.852300        0.832930         0.881356           0.917676       01:19
5         0.196468    1.963423    0.854722        0.830508         0.881356           0.895884       01:19
6         0.221572    1.871300    0.854722        0.837772         0.878935           0.905569       01:19
7         0.208470    1.923441    0.866828        0.830508         0.886199           0.903148       01:19
8         0.196030    1.957731    0.869249        0.823245         0.881356           0.907990       01:19
9         0.212627    1.908893    0.854722        0.837772         0.886199           0.907990       01:19
@outsidersCustomCallback: Training completed and best 276a model loaded!

Model UNFROZEN [b].
>> @276b --- pct_start: 0.2 --- learning_rate: 1.9054607491852948e-06
epoch     train_loss  valid_loss  accuracyCustom  accuracyTopDown  accuracyFrontAway  accuracyTuner  time
0         0.285612    1.850545    0.859564        0.830508         0.871671           0.912833       01:35
1         0.245497    1.741573    0.869249        0.840194         0.876513           0.912833       01:34
2         0.231375    1.810342    0.857143        0.854722         0.864407           0.912833       01:34
3         0.219720    1.930089    0.845036        0.823245         0.871671           0.895884       01:34
4         0.203985    1.821503    0.861985        0.813559         0.881356           0.917676       01:34
5         0.230706    1.764397    0.835351        0.866828         0.859564           0.912833       01:34
6         0.221303    1.877122    0.835351        0.840194         0.881356           0.917676       01:34
7         0.191439    1.804512    0.849879        0.840194         0.876513           0.907990       01:34
8         0.231850    1.716849    0.869249        0.845036         0.874092           0.929782       01:34
9         0.270165    1.789981    0.835351        0.849879         0.881356           0.922518       01:34
@outsidersCustomCallback: Training completed and best 276b model loaded!
Time Elapsed ~ 02h:01m:04s
-- [   276] - 0.8668 - 0.8281 - 0.8596 - 0.9346 - 02:01
Batch Size: 16, Image Size: 328, Epochs: 10

Model FROZEN [a].
>> @328a --- pct_start: 0.2 --- learning_rate: 0.0002290867705596611
epoch     train_loss  valid_loss  accuracyCustom  accuracyTopDown  accuracyFrontAway  accuracyTuner  time
0         0.553364    1.976522    0.859564        0.825666         0.854722           0.898305       01:44
1         0.467865    1.964584    0.859564        0.840194         0.847458           0.888620       01:44
2         0.392985    1.988929    0.847458        0.861985         0.859564           0.893462       01:44
3         0.355446    1.988596    0.854722        0.811138         0.878935           0.888620       01:44
4         0.370991    1.876261    0.864407        0.832930         0.886199           0.888620       01:44
5         0.337653    1.904391    0.847458        0.847458         0.869249           0.905569       01:44
6         0.319891    1.848454    0.857143        0.847458         0.874092           0.912833       01:44
7         0.277626    1.780841    0.859564        0.849879         0.869249           0.907990       01:44
8         0.307194    1.824329    0.857143        0.842615         0.869249           0.910412       01:44
9         0.242807    1.933026    0.845036        0.859564         0.864407           0.895884       01:44
@outsidersCustomCallback: Training completed and best 328a model loaded!

Model UNFROZEN [b].
>> @328b --- pct_start: 0.2 --- learning_rate: 3.0199516913853586e-05
epoch     train_loss  valid_loss  accuracyCustom  accuracyTopDown  accuracyFrontAway  accuracyTuner  time
0         0.402232    1.870008    0.845036        0.857143         0.874092           0.912833       02:04
1         0.381289    2.369496    0.762712        0.847458         0.835351           0.876513       02:04
2         0.366705    1.954165    0.832930        0.832930         0.866828           0.905569       02:04
3         0.314587    1.989272    0.866828        0.813559         0.891041           0.912833       02:04
4         0.264575    1.893274    0.845036        0.866828         0.881356           0.905569       02:04
5         0.230783    1.789603    0.825666        0.864407         0.886199           0.917676       02:04
6         0.221855    1.764852    0.854722        0.861985         0.881356           0.922518       02:04
7         0.200588    1.956108    0.857143        0.840194         0.869249           0.907990       02:04
8         0.196278    1.826851    0.840194        0.866828         0.886199           0.910412       02:04
9         0.213793    1.866301    0.854722        0.864407         0.874092           0.917676       02:04
@outsidersCustomCallback: Training completed and best 328b model loaded!
>> @328bf --- pct_start: 0.2 --- learning_rate: 3.0199516913853586e-06
epoch     train_loss  valid_loss  accuracyCustom  accuracyTopDown  accuracyFrontAway  accuracyTuner  time
0         0.197537    1.746381    0.845036        0.859564         0.874092           0.917676       02:04
1         0.216144    1.738444    0.861985        0.859564         0.891041           0.927361       02:04
2         0.216299    1.832985    0.864407        0.840194         0.876513           0.920097       02:04
3         0.205270    1.794844    0.842615        0.861985         0.893462           0.920097       02:04
4         0.167609    1.787629    0.832930        0.864407         0.878935           0.912833       02:04
5         0.153770    1.856116    0.857143        0.864407         0.866828           0.915254       02:04
6         0.206295    1.739663    0.854722        0.857143         0.886199           0.912833       02:04
7         0.199368    1.988287    0.857143        0.828087         0.869249           0.907990       02:04
8         0.200842    1.728007    0.859564        0.874092         0.878935           0.915254       02:04
9         0.180742    1.832843    0.849879        0.857143         0.881356           0.917676       02:04
@outsidersCustomCallback: Training completed and best 328bf model loaded!
Time Elapsed ~ 03h:03m:36s
-- [   328] - 0.8668 - 0.8281 - 0.8596 - 0.9346 - 03:03
accuracies@e2eT: {'Custom': 0.8039, 'Top-Down': 0.6901, 'Front-Away': 0.7482, 'Tuner': 0.2881}
Learner pkl and pt checkpoints created successfully
e2eT_MaxA: 0.9346 @03h:03m:54s
Training completed @e2eEnsembleTunerTraining ->> [bf75]-181022.1321 ->- e2eET.liveStream-DHG1428.3D.7G-[cm_td_fa]-i30.10
# ------------------------------------------------------------------------
# ------------------------------------------------------------------------
