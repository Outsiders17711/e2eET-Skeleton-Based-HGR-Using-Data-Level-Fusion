{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## e2eET Skeleton Based HGR Using Data-Level Fusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2N5i0LEcxRtT"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from scipy import ndimage, io\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _resize_gestures(in_gest_seqs, target_length=250):\n",
        "    \"\"\"Resize the time series by interpolating them to the same length\"\"\"\n",
        "\n",
        "    out_gest_seqs = []\n",
        "    for sequence in in_gest_seqs:\n",
        "        zoomed_skeletons = []\n",
        "        for skeleton in range(np.size(sequence, 1)):\n",
        "            _zoom_skel = ndimage.zoom(sequence.T[skeleton], target_length / len(sequence), mode=\"reflect\")\n",
        "            zoomed_skeletons.append(_zoom_skel)\n",
        "\n",
        "        out_gest_seqs.append(np.array(zoomed_skeletons).T)\n",
        "\n",
        "    return np.array(out_gest_seqs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_mat_gestures(type, resize_length, root, cleanup=True, verbose=False):\n",
        "    \"\"\"\n",
        "    Get the 3D pose gestures sequences, and their associated labels.\n",
        "    Output:  a tuple of (gestures, labels, details).\n",
        "    \"\"\"\n",
        "\n",
        "    # _____\n",
        "    assert \"LMDHG\" in root, \"Check that the correct dataset folder is provided!\"\n",
        "    assert type == \"3d\", \"LMDHG only contains 3D data!\"\n",
        "\n",
        "    translation = {\n",
        "        \"ATTRAPER_MAIN_LEVEE\": [\"AttraperMainLevee\", \"CatchWithTwoHands\"],\n",
        "        \"ATTRAPER\": [\"Attraper\", \"Catch\"],\n",
        "        \"C\": [\"C\", \"DrawC\"],\n",
        "        \"DEFILER_DOIGT\": [\"DefilerDoigt\", \"Scroll\"],\n",
        "        \"LIGNE\": [\"Ligne\", \"DrawLine\"],\n",
        "        \"PIVOTER\": [\"Pivoter\", \"Rotate\"],\n",
        "        \"POINTER_MAIN_LEVEE\": [\"PointerMainLevee\", \"PointToWithTwoHands\"],\n",
        "        \"POINTER_PROLONGE\": [\"PointerMainLevee\", \"PointToWithTwoHands\"],  # [NOTE] unknown class; skip\n",
        "        \"POINTER\": [\"Pointer\", \"PointTo\"],\n",
        "        \"SECOUER_BAS\": [\"SecouerBas\", \"ShakeDown\"],\n",
        "        \"SECOUER_POING_LEVE\": [\"SecouerPoingLeve\", \"ShakeWithTwoHands\"],\n",
        "        \"SECOUER\": [\"Secouer\", \"Shake\"],\n",
        "        \"TRANCHER\": [\"Trancher\", \"Slice\"],\n",
        "        \"CISEAUX\": [\"Trancher\", \"Slice\"],  # [NOTE] unknown class; skip\n",
        "        \"ZOOM\": [\"Zoom\", \"Zoom\"],\n",
        "        \"REPOS\": [\"Repos\", \"Resting\"],  # [NOTE] filler class; skip\n",
        "    }\n",
        "\n",
        "    filenames = list(Path(root).rglob(\"*Datafile*.mat\"))\n",
        "    \n",
        "    # _____\n",
        "    gestures = []\n",
        "    labels = []\n",
        "    details = []\n",
        "    skipped_classes = {\"CISEAUX\": 0, \"POINTER_PROLONGE\": 0, \"REPOS\": 0}\n",
        "\n",
        "    for f in filenames:\n",
        "        f_data = io.loadmat(f)\n",
        "        if verbose: print(f\"{f= }\")\n",
        "\n",
        "        f_annotations = f_data[\"Anotations\"] - 1  # subtract 1 to switch from MATLAB to python indexing\n",
        "        f_labels = [entry[0] for entry in f_data[\"labels\"][:, 0]]\n",
        "        f_skeletons = [entry[0] for entry in f_data[\"skeleton\"]]\n",
        "\n",
        "        for (_stt_idx, _stp_idx), _lbl in zip(f_annotations, f_labels):\n",
        "            if cleanup and _lbl in [\"CISEAUX\", \"POINTER_PROLONGE\", \"REPOS\"]:\n",
        "            # if cleanup and _lbl == [\"CISEAUX\"]:  # [NOTE] alternate filter; not used\n",
        "                skipped_classes[_lbl] += 1\n",
        "                continue\n",
        "\n",
        "            _lbl = translation[_lbl][-1]\n",
        "            _deets = f\"{_lbl}-{f.stem}_{_stt_idx+1}_{_stp_idx+1}\"\n",
        "            _gesture = np.array(f_skeletons[_stt_idx:_stp_idx+1])\n",
        "            _gesture = _gesture.reshape(_gesture.shape[0], -1)\n",
        "\n",
        "            gestures.append(_gesture)\n",
        "            labels.append(_lbl)\n",
        "            details.append(_deets)\n",
        "            if verbose: print(f\"{_gesture.shape=} | {_deets=}\")\n",
        "\n",
        "        # break\n",
        "\n",
        "    if resize_length: gestures = _resize_gestures(gestures, target_length=resize_length)\n",
        "    print(f\"{len(gestures)=} | {len(labels)=} | {len(details)=}\")\n",
        "    print(f\"{skipped_classes=}\")\n",
        "    assert len(gestures) == len(labels) == len(details)\n",
        "    return gestures, labels, details\n",
        "\n",
        "# load_mat_gestures(type=\"3d\", resize_length=None, root=\"../../LMDHG\", verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _write_data(data, filepath):\n",
        "    \"\"\"Save the dataset to a file. Note: data is a dict with keys 'X_train', ...\"\"\"\n",
        "\n",
        "    with open(filepath, \"wb\") as output_file: pickle.dump(data, output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_pckl_data(filepath):\n",
        "    \"\"\"\n",
        "    Returns hand gesture sequences (X) and their associated labels (Y).\n",
        "    \"\"\"\n",
        "\n",
        "    file = open(filepath, \"rb\")\n",
        "    data = pickle.load(file, encoding=\"latin1\") # change to 'latin1' to 'utf8' if the data does not load\n",
        "    file.close()\n",
        "\n",
        "    return (\n",
        "        data[\"X_train\"], data[\"X_valid\"],\n",
        "        data[\"train_labels\"], data[\"valid_labels\"],\n",
        "        data[\"train_details\"], data[\"valid_details\"],\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _get_df(i_deets, subset):\n",
        "    assert subset in [\"train\", \"valid\"]\n",
        "    dfs = range(1, 36) if (subset == \"train\") else range(36, 51)\n",
        "    df = int(i_deets.split(\"-\")[-1].split(\"_\")[0].replace(\"DataFile\", \"\"))\n",
        "    return df in dfs\n",
        "\n",
        "def create_LMDHG_paper_split(type, root, resize_length=None, seed=17711, save_path=None):\n",
        "    assert type in [\"2d\", \"3d\"], \"Data type has to be specified ['2d' / '3d']\"\n",
        "    \n",
        "    # load the dataset gesture sequences from file(s)\n",
        "    gestures, labels, details = load_mat_gestures(type, resize_length, root)\n",
        "    print(\">>> <gestures, labels, details> loaded successfully!\")\n",
        "\n",
        "    # split into train and validation subsets\n",
        "    idxs_valid = [i for i, i_deets in enumerate(details) if _get_df(i_deets, \"valid\")]\n",
        "    idxs_train = [i for i, i_deets in enumerate(details) if _get_df(i_deets, \"train\")]\n",
        "\n",
        "    X_train, X_valid = gestures[idxs_train], gestures[idxs_valid]  # type:ignore\n",
        "    train_labels = np.array(labels)[idxs_train].tolist()\n",
        "    valid_labels = np.array(labels)[idxs_valid].tolist()\n",
        "    train_details = np.array(details)[idxs_train].tolist()\n",
        "    valid_details = np.array(details)[idxs_valid].tolist()\n",
        "    print(f\">>> {type} training ({X_train.shape}) and validation ({X_valid.shape}) data created.\")\n",
        "    \n",
        "    # save the test-train data to disk\n",
        "    if save_path is None: save_path = \"../datasets\"\n",
        "    save_path = f\"{save_path}/LMDHG_{type}_dictPaperSplit_l{resize_length}_s{len(gestures)}.pckl\"\n",
        "\n",
        "    data = {\n",
        "        \"X_train\": X_train, \"X_valid\": X_valid,\n",
        "        \"train_labels\": train_labels, \"valid_labels\": valid_labels,\n",
        "        \"train_details\": train_details, \"valid_details\": valid_details,\n",
        "    }\n",
        "    _write_data(data, filepath=save_path)\n",
        "    print(f\">>> LMDHG Paper train-valid data written to <{save_path}> successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len(gestures)=609 | len(labels)=609 | len(details)=609\n",
            "skipped_classes={'CISEAUX': 22, 'POINTER_PROLONGE': 23, 'REPOS': 579}\n",
            ">>> <gestures, labels, details> loaded successfully!\n",
            ">>> 3d training ((415, 750, 138)) and validation ((194, 750, 138)) data created.\n",
            ">>> LMDHG Paper train-valid data written to <../datasets/LMDHG_3d_dictLPS_l750_s609.pckl> successfully!\n"
          ]
        }
      ],
      "source": [
        "create_LMDHG_paper_split(type=\"3d\", root=\"../datasets/LMDHG\", resize_length=750)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "deep_learning_hand_gesture_recognition_01_data_download.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 ('hlu')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "fd523941f93840f3066dc30de95cef5f0b3787e3e58410dcba83902e24288dc0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
